# Double Descent



Double Descent is a phenomenon that has arisen in relatively recent years due to scaling in great magnitude Neural Networks. It is a phenomenon that generated a storm of publications and discussion because it contradicts one of the core foundations of Machine Learning: The bias variance trade off.  This repository is a demo of the subject.



In the folder **report**, an explanation of the theory is included with the file report.pdf



In the folder code, Python scripts are included for the two examples we were concerned with (navigate to the folder Path "Double\_Descent"):



* Cubic Natural Splines 



```bash

C:\\Double\_Descent\\code> python NaturalSplines\_example.py

```



and



* Random Fourier Features

```bash

C:Double\_Descent\\code> python rff\_example.py

```



